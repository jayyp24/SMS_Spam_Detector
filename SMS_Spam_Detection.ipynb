{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the visualization\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Label                                                SMS\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...    ...                                                ...\n",
      "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5570   ham               Will ü b going to esplanade fr home?\n",
      "5571   ham  Pity, * was in mood for that. So...any other s...\n",
      "5572   ham  The guy did some bitching but I acted like i'd...\n",
      "5573   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "csv_file_path = r\"C:\\Users\\acer\\Downloads\\SMSSpamCollection.csv\"\n",
    "\n",
    "\n",
    "labels = []\n",
    "sms_messages = []\n",
    "\n",
    "with open(csv_file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        \n",
    "        label = line[:4].strip()\n",
    "        message = line[4:].strip()\n",
    "        labels.append(label)\n",
    "        sms_messages.append(message)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Label': labels, 'SMS': sms_messages})\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_mapping = {'ham': 0, 'spam': 1}\n",
    "\n",
    "\n",
    "df['Label'] = df['Label'].map(label_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Label                                                SMS\n",
      "0         0  Go until jurong point, crazy.. Available only ...\n",
      "1         0                      Ok lar... Joking wif u oni...\n",
      "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         0  U dun say so early hor... U c already then say...\n",
      "4         0  Nah I don't think he goes to usf, he lives aro...\n",
      "...     ...                                                ...\n",
      "5569      1  This is the 2nd time we have tried 2 contact u...\n",
      "5570      0               Will ü b going to esplanade fr home?\n",
      "5571      0  Pity, * was in mood for that. So...any other s...\n",
      "5572      0  The guy did some bitching but I acted like i'd...\n",
      "5573      0                         Rofl. Its true to its name\n",
      "\n",
      "[5574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "400000 words loaded!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['processed_text'] = df['SMS'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "def load_glove_model(file):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(file, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "glove_path = r'C:\\Users\\acer\\Downloads\\glove.6B\\glove.6B.100d.txt'  # Update with your path\n",
    "glove_model = load_glove_model(glove_path) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def text_to_glove_vector(text, glove_model):\n",
    "    words = word_tokenize(text.lower())\n",
    "    word_vectors = [glove_model[word] for word in words if word in glove_model]\n",
    "    \n",
    "    if not word_vectors:\n",
    "        return np.zeros(100)  \n",
    "    else:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n",
    "df['glove_vector'] = df['processed_text'].apply(lambda x: text_to_glove_vector(x, glove_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.stack(df['glove_vector'].values)  \n",
    "y = df['Label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Accuracy: 0.9617453676031081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1447\n",
      "           1       0.82      0.92      0.87       226\n",
      "\n",
      "    accuracy                           0.96      1673\n",
      "   macro avg       0.90      0.94      0.92      1673\n",
      "weighted avg       0.96      0.96      0.96      1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "parameters = {'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001]}\n",
    "svm_model = SVC()\n",
    "grid_search = GridSearchCV(svm_model, parameters, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "\n",
    "\n",
    "y_scores = best_model.decision_function(X_test)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "\n",
    "def adjusted_predict(model, X, threshold=0):\n",
    "    scores = model.decision_function(X)\n",
    "    return [1 if score > threshold else 0 for score in scores]\n",
    "\n",
    "\n",
    "adjusted_pred = adjusted_predict(best_model, X_test, threshold=-0.5)  # Adjust threshold as needed\n",
    "print(\"Adjusted Accuracy:\", accuracy_score(y_test, adjusted_pred))\n",
    "print(classification_report(y_test, adjusted_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sensitive_keywords = [\"password\", \"bank account\", \"credit card\", \"social security\", \n",
    "                      \"login details\", \"pin\", \"confirm password\", \"verify account\"]\n",
    "\n",
    "def contains_sensitive_info(sms, keywords):\n",
    "    sms_lower = sms.lower()\n",
    "    return any(keyword in sms_lower for keyword in keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(sms):\n",
    "    analysis = TextBlob(sms)\n",
    "    return analysis.sentiment.polarity  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message is classified as: Spam\n"
     ]
    }
   ],
   "source": [
    "def predict_sms_with_threshold(sms, glove_model, model, threshold=0):\n",
    "    if contains_sensitive_info(sms, sensitive_keywords):\n",
    "        return 'Spam'\n",
    "    \n",
    "    sentiment_score = get_sentiment(sms)\n",
    "    if sentiment_score < -0.5:  \n",
    "        return 'Spam (Negative Sentiment)'\n",
    "    \n",
    "    sms_vector = text_to_glove_vector(sms, glove_model)\n",
    "    score = model.decision_function([sms_vector])\n",
    "    prediction = 1 if score > threshold else 0\n",
    "    return 'Spam' if prediction == 1 else 'Ham'\n",
    "\n",
    "\n",
    "sms = \"Congratulations! You've been selected to win a free iPhone! Click the link to claim your prize now!\"\n",
    "threshold = -0.5 \n",
    "prediction = predict_sms_with_threshold(sms, glove_model, best_model, threshold)\n",
    "print(f\"The message is classified as: {prediction}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
